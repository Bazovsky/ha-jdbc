<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE document PUBLIC "-//APACHE//DTD Documentation V2.0//EN" "http://forrest.apache.org/dtd/document-v20.dtd">
<document> 
	<header> 
		<title>Documentation</title>
	</header> 
	<body>
		<section>
			<title>Requirements</title>
			<ul>
				<li>Java Runtime Environment 1.5 (Java 1.4 also supported<a href="#Java1.4">*</a>)</li>
				<li>JDBC 3.0 compliant driver (Type IV recommended)</li>
				<li>All databases in cluster must initially be in sync.</li>
			</ul>
			<section id="Java1.4">
				<title>Using Java 1.4</title>
				<p>
					As of version 1.1, HA-JDBC ships 2 binary distributions.  The default binary requires Java 1.5.
					A Java 1.4 compatible binary is generated using <a href="http://retrotranslator.sourceforge.net">Retrotranslator</a>.
					Consequently, this binary has a couple of additional runtime dependencies, contained in the <code>/lib/runtime-1.4</code> directory of the distribution.
				</p>
				<p>
					HA-JDBC requires a running JMX 1.2+ mbean server.
					While Java 1.5 includes Sun's JMX reference implementation, Java 1.4 does not.
					Therefore, if your application server or servlet container does not include a JMX 1.2 implementation, it is up to you to supply one.
					Below is a list of popular and free JMX implementations available to you:
				</p>
				<ul>
					<li><a href="http://java.sun.com/products/JavaManagement/index.jsp">Sun's JMX Reference Implemenation</a></li>
					<li><a href="http://mx4j.sourceforge.net">MX4J</a></li>
					<li><a href="http://www.xmojo.org/products/xmojo">XMOJO</a></li>
					<li><a href="http://www.jboss.org/developers/projects/jboss/jbossmx">JBossMX</a></li>
					<li><a href="http://www.huihoo.org/jfox/jfoxmx/index.html">JFoxMX</a></li>
				</ul>
			</section>
		</section>
		<section>
			<title>Configuration</title>
			<section>
				<title>Database Cluster Configuration</title>
				<p>
					Configuration for HA-JDBC managed database clusters is contained in a single XML file.
					The format of the configuration file should match the <a href="dtd/ha-jdbc-1.1.dtd">DTD</a>.
				</p>
				<p>Sample configuration file containing both types of deployment setups:</p>
				<source><![CDATA[
<?xml version="1.0"?>
<!DOCTYPE ha-jdbc PUBLIC "-//HA-JDBC//DTD HA-JDBC 1.1//EN"
  "http://ha-jdbc.sourceforge.net/dtd/ha-jdbc-1.1.dtd">
<ha-jdbc>
  <sync id="diff" class="net.sf.hajdbc.sync.DifferentialSynchronizationStrategy"></sync>
  <sync id="full" class="net.sf.hajdbc.sync.FullSynchronizationStrategy"></sync>
  <sync id="passive" class="net.sf.hajdbc.sync.PassiveSynchronizationStrategy"></sync>
  <cluster id="cluster1" dialect="PostgreSQL" balancer="simple" default-sync="diff">
    <database id="database1" weight="1">
      <driver>org.postgresql.Driver</driver>
      <url>jdbc:postgresql://server1/database</url>
      <user>postgres</user>
      <password>password</password>
    </database>
    <database id="database2" weight="2">
      <driver>org.postgresql.Driver</driver>
      <url>jdbc:postgresql://server2/database</url>
      <user>postgres</user>
      <password>password</password>
    </database>
  </cluster>
  <cluster id="cluster2" dialect="MySQL" balancer="random" default-sync="full">
    <datasource id="database1" weight="1">
      <name>java:comp/env/jdbc/Database1</name>
    </datasource>
    <datasource id="database2" weight="2">
      <name>java:comp/env/jdbc/Database2</name>
    </datasource>
  </cluster>
</ha-jdbc>
]]></source>
				<p>
					The algorithm used to locate the configuration file resource at runtime is as follows:
				</p>
				<ol>
					<li>
						<p>Read the resource name from the <code>ha-jdbc.configuration</code> system property.  If not defined, the default value "<code>ha-jdbc.xml</code>" is used.</p>
					</li>
					<li>
						<p>Attempt to interpret the resource name as a URL.</p>
					</li>
					<li>
						<p>If the resource name cannot be converted to a URL, then search for the resource in the classpath using the following algorithm:</p>
						<ol>
							<li>Search for resource using the thread context class loader.</li>
							<li>If not found, search for resource using the class loader of the current class.</li>
							<li>If not found, search for resource using the system class loader.</li>
						</ol>
					</li>
					<li>
						<p>If still not found, throw an exception back to the caller.</p>
					</li>
				</ol>
			</section>
			<section>
				<title>Application Configuration</title>
				<p>
					To configure HA-JDBC in your application server, simply replace your existing references to your JDBC driver and url accordingly.
				</p>
				<section>
					<title>Server configuration examples</title>
					<ul>
						<li>
							<p><a href="http://jetty.mortbay.org">Jetty</a> (using <a href="http://xapool.objectweb.org">c3p0</a>)</p>
							<source><![CDATA[
<Configure class="org.mortbay.jetty.plus.Server">
  <Call name="addService">
    <Arg>
      <New class="org.mortbay.jetty.plus.DefaultDataSourceService">
        <Set name="Name">DataSourceService</Set>
        <Call name="addDataSource">
          <Arg>jdbc/Cluster</Arg>
          <Arg>
            <New class="com.mchange.v2.c3p0.ComboPooledDataSource">
              <Set name="DriverClass">net.sf.hajdbc.sql.Driver</Set>
              <Set name="JdbcUrl">jdbc:ha-jdbc:cluster1</Set>
              <Set name="User">postgres</Set>
              <Set name="Password">password</Set>
              <Set name="MinPoolSize">5</Set>
              <Set name="MaxPoolSize">20</Set>
              <Set name="MaxIdleTime">360</Set>
              <Set name="PreferredTestQuery">SELECT 1</Set>
              <Set name="IdleConnectionTestPeriod">60</Set>
            </New>
          </Arg>
        </Call>
      </New>
    </Arg>
  </Call>
</Configure>
]]></source>
						</li>
						<li>
							<p><a href="http://jetty.mortbay.org">Jetty</a> (using <a href="http://xapool.objectweb.org">XAPool</a>)</p>
							<source><![CDATA[
<Configure class="org.mortbay.jetty.plus.Server">
  <Call name="addService">
    <Arg>
      <New class="org.mortbay.jetty.plus.DefaultDataSourceService">
        <Set name="Name">DataSourceService</Set>
        <Call name="addConnectionPoolDataSource">
          <Arg>jdbc/Cluster</Arg>
          <Arg>
            <New class="org.enhydra.jdbc.standard.StandardConnectionPoolDataSource">
              <Set name="DriverName">net.sf.hajdbc.sql.Driver</Set>
              <Set name="Url">jdbc:ha-jdbc:cluster1</Set>
            </New>
          </Arg>
          <Set name="User">postgres</Set>
          <Set name="Password">password</Set>
          <Set name="MinSize">5</Set>
          <Set name="MaxSize">50</Set>
          <Set name="CheckLevelObject">2</Set>
          <Set name="JdbcTestStmt">SELECT 1</Set>
        </Call>
      </New>
    </Arg>
  </Call>
</Configure>
]]></source>
						</li>
						<li>
							<p><a href="http://jakarta.apache.org/tomcat">Tomcat</a> (using <a href="http://jakarta.apache.org/commons/dbcp">DBCP</a>)</p>
							<source><![CDATA[
<Resource name="jdbc/Cluster" auth="Container" type="javax.sql.DataSource"/>
<ResourceParams name="jdbc/Cluster">
  <parameter>
    <name>factory</name>
    <value>org.apache.commons.dbcp.BasicDataSourceFactory</value>
  </parameter>
  <parameter>
    <name>driverClassName</name>
    <value>net.sf.hajdbc.sql.Driver</value>
  </parameter>
  <parameter>
    <name>url</name>
    <value>jdbc:ha-jdbc:cluster</value>
  </parameter>
  <parameter>
    <name>username</name>
    <value>postgres</value>
  </parameter>
  <parameter>
    <name>password</name>
    <value>password</value>
  </parameter>
  <parameter>
    <name>maxActive</name>
    <value>100</value>
  </parameter>
  <parameter>
    <name>maxWait</name>
    <value>10000</value>
  </parameter>
</ResourceParams>
]]></source>
						</li>
						<li>
							<p>More server configuration examples coming soon...</p>
						</li>
					</ul>
				</section>
			</section>
			<section id="dialect">
				<title>Dialect</title>
				<p>
					The <code>dialect</code> attribute of a cluster determines the SQL syntax used for a given task.
					The value specified for this attribute is either the name of a class that implements <a href="api/net/sf/hajdbc/Dialect.html">net.sf.hajdbc.Dialect</a> (custom implementations are allowed), or, more conveniently, a pre-defined alias.
					If the dialect attribute is omitted, then <a href="api/net/sf/hajdbc/dialect/DefaultDialect.html">net.sf.hajdbc.dialect.DefaultDialect</a> will be used.
				</p>
				<p>e.g.</p>
				<source><![CDATA[
<cluster id="..." balancer="..." default-sync="...">
  <!-- Uses default dialect -->
</cluster>
<cluster id="..." dialect="net.sf.hajdbc.dialect.PostgreSQLDialect" balancer="..." default-sync="...">
  <!-- Uses PostgreSQL dialect -->
</cluster>
<cluster id="..." dialect="PostgreSQL" balancer="..." default-sync="...">
  <!-- Uses PostgreSQL dialect -->
  <!-- Aliases are not case sensitive -->
</cluster>
]]></source>
				<p>
					HA-JDBC ships with the following dialect implemenations:
				</p>
				<table>
					<tr>
						<th>Vendor</th>
						<th>Dialect</th>
						<th>Aliases</th>
					</tr>
					<tr>
						<td>PostgreSQL</td>
						<td><a href="api/net/sf/hajdbc/dialect/PostgreSQLDialect.html">net.sf.hajdbc.dialect.PostgreSQLDialect</a></td>
						<td>postgresql</td>
					</tr>
					<tr>
						<td>MySQL MaxDB, Oracle</td>
						<td><a href="api/net/sf/hajdbc/dialect/MaxDBDialect.html">net.sf.hajdbc.dialect.MaxDBDialect</a></td>
						<td>maxdb, oracle</td>
					</tr>
					<tr>
						<td>Apache Derby</td>
						<td><a href="api/net/sf/hajdbc/dialect/DerbyDialect.html">net.sf.hajdbc.dialect.DerbyDialect</a></td>
						<td>derby</td>
					</tr>
					<tr>
						<td>HSQLDB</td>
						<td><a href="api/net/sf/hajdbc/dialect/HSQLDBDialect.html">net.sf.hajdbc.dialect.HSQLDBDialect</a></td>
						<td>hsqldb</td>
					</tr>
					<tr>
						<td>IBM DB2</td>
						<td><a href="api/net/sf/hajdbc/dialect/DB2Dialect.html">net.sf.hajdbc.dialect.DB2Dialect</a></td>
						<td>db2</td>
					</tr>
					<tr>
						<td>Default (SQL standard)</td>
						<td><a href="api/net/sf/hajdbc/dialect/DefaultDialect.html">net.sf.hajdbc.dialect.DefaultDialect</a></td>
						<td>mysql, firebird, ingres, mckoi</td>
					</tr>
				</table>
			</section>
			<section>
				<title>Cluster Balancer</title>
				<p>
					When executing a read request from the cluster, HA-JDBC uses the specified balancer strategy to determine which database to use.
					Each database can define a weight to affect how it is prioritized by the balancer.
					If no weight is specified for a given database, it is assumed to be 1.
				</p>
				<p>
					HA-JDBC supports four types of read request balancers:
				</p>
				<dl>
					<dt><strong>Simple</strong></dt>
					<dd>
						Requests are always sent to the node with the highest weight.
					</dd>
					<dt><strong>Random</strong></dt>
					<dd>
						Requests are sent to a random node.
						Node weights affect the probability that a given node will be chosen.
						The probability that a node will be chosen = <em>weight</em> / <em>total-weight</em>.
					</dd>
					<dt><strong>Round-Robin</strong></dt>
					<dd>
						Requests are sent to each node in succession.
						A node of weight <em>n</em> will receive <em>n</em> requests before the balancer moves on to the next node.
					</dd>
					<dt><strong>Load</strong></dt>
					<dd>
						Requests are sent to the node with the smallest load.
						Node weights affect the calculated load of a given node.
						The load of a node = <em>concurrent-requests</em> / <em>weight</em>.
					</dd>
				</dl>
				<note>
					In general, a node with a weight of 0 or less will never service a request unless it is the last node in the cluster.
				</note>
			</section>
			<section>
				<title>Distributed environment</title>
				<p>
					If you use HA-JDBC to access the same database cluster from more than one JVM (e.g. an application server cluster), your HA-JDBC configuration must use the <![CDATA[<distributable/>]]> feature.
					HA-JDBC leverages the <a href="http://www.jgroups.org">JGroups</a> project to handle communication between database clusters across servers.
				</p>
				<p>e.g.</p>
				<source><![CDATA[
<ha-jdbc>
  <distributable/>
  <sync id="..." class="..."></sync>
  <cluster id="..." balancer="..." default-sync="...">
    <!-- ... -->
  </cluster>
</ha-jdbc>
]]></source>
				<p>
					The <![CDATA[<distributable/>]]> element may contain an optional <code>protocol</code> attribute which specifies one of the following:
				</p>	
				<ul>
					<li>Property string representation of the JGroups protocol stack. (e.g. see below)</li>
					<li>Name of a system resource containing the JGroups XML configuration. (e.g. default.xml - located within the JGroups jar file)</li>
					<li>URL of the JGroups XML configuration file.</li>
					<li>Path of the JGroups XML configuration on the local file system.</li>
				</ul>
				<p>
					If left unspecified, HA-JDBC will use the protocol stack specified in <em>default-minimalthreads.xml</em> contained within the JGroups distribution.
				</p>
				<p>
					See the JGroup's <a href="http://www.jboss.com/wiki/Wiki.jsp?page=JGroups">Wiki</a> for assistance with customizing the protocol stack.
				</p>
			</section>
			<section>
				<title>Unique identifier generation</title>
				<p>The following traditional mechanisms for generating unique identifiers are problematic for clustered database environments:</p>
				<ul>
					<li>Identity columns (only supported by MySQL, HSQLDB, DB2, MS SQL Server, Sybase, etc.) fetched using the JDBC 3.0 <code>ResultSet.getGeneratedKeys()</code> method</li>
					<li>Sequences (only supported by PostgreSQL, MySQL MaxDB (fka SAP DB), Firebird (fka Interbase), Mckoi, Oracle, DB2, etc.)</li>
				</ul>
				<p>
					In general, for unique identifier generation to function correctly, each database node within a cluster needs to independently generate the same sets of identifiers.
					Because of the distributed nature of HA-JDBC, the execution order of 2 simulaneous requests for a new unique identifier cannot be guananteed to be the same on each database.
					In other words, HA-JDBC cannot guarantee that the same identifier will be generated for each database in the cluster.
					Another reason not to use either of these mechanisms is that they are not supported by every DBMS.
				</p>
				<p>The following alternative unique identifier generation methods are certain to function properly with HA-JDBC for any database:</p>
				<ul>
					<li>High-Low algorithm (often implemented using a Stateless Session EJB)</li>
					<li>UUID algorithms</li>
					<li>Others?</li>
				</ul>
				<p>
					Object-relation mapping (ORM) frameworks (e.g. Hibernate, OJB, Cayanne) typically include implementations of these mechanisms.
				</p>
				<!--p>
					As of version 1.1, HA-JDBC supports those unique identifier generation mechanisms that were problematic in version 1.0 (i.e. identity columns and sequences).
					To support identity columns and sequences, HA-JDBC will acquire a distributable lock on the specific table or sequence before executing the appropriate statements.
					
				</p>
				<section>
					<title>Supported unique identifier mechanisms</title>
					<table>
						<tr>
							<th>Mechanism</th>
							<th>Supported Databases</th>
							<th>Usage</th>
							<th>Consequences</th>
						</tr>
						<tr>
							<td>identity</td>
							<td>MySQL, HSQLDB, Derby/Cloudscape,<br/>DB2, Sybase/SQL Server,<br/>Informix</td>
							<td>INSERT [INTO] my_table ...</td>
							<td>INSERT statements require mutually exclusive lock on table name.</td>
						</tr>
						<tr>
							<td>sequence-SQL:2003</td>
							<td>SQL:2003 syntax</td>
							<td>next value from my_sequence</td>
							<td>Requires mutually exclusive lock on sequence name.</td>
						</tr>
						<tr>
							<td>sequence-PostgreSQL</td>
							<td>PostgreSQL, Mckoi</td>
							<td>nextval('my_sequence')</td>
							<td>Requires mutually exclusive lock on sequence name.</td>
						</tr>
						<tr>
							<td>sequence-MaxDB</td>
							<td>MaxDB/SAPDB, One$DB/Daffodil,<br/>Axion, Oracle, Informix</td>
							<td>my_sequence.nextval</td>
							<td>Requires mutually exclusive lock on sequence name.</td>
						</tr>
						<tr>
							<td>sequence-Firebird</td>
							<td>Firebird/Interbase</td>
							<td>gen_id('my_sequence', 1)</td>
							<td>Requires mutually exclusive lock on sequence name.</td>
						</tr>
						<tr>
							<td>sequence-DB2</td>
							<td>DB2</td>
							<td>nextval from my_sequence</td>
							<td>Requires mutually exclusive lock on sequence name.</td>
						</tr>
						<tr>
							<td>other</td>
							<td>Any database</td>
							<td>Table high-low algorithm, UUID, etc.</td>
							<td>No locking required.</td>
						</tr>
					</table>
					<p>
						HA-JDBC 1.1 requires that the unique identifier generation mechansim be specified using the <em>primary-keys</em> attribute for a given cluster.
						The list of acceptable values is specified in the <em>Mechanism</em> column above.
					</p>
					<p>e.g.</p>
					<source><![CDATA[
	<ha-jdbc>
	  <cluster id="..." balancer="..." default-sync="..." primary-keys="other">
	  </cluster>
	</ha-jdbc>
	]]></source>
				</section>
				<section>
					<title>Performance</title>
					<p>
						As you may have guessed, there are performance implications to using identity columns and sequences.
						Both algorithms introduce per statement regular expression matching and mutex costs, the latter being even more costly for distruted environments.
						Fortunately, the performance penalty for sequences may be improved significantly by utilizing what Hibernate calls a <a href="http://www.hibernate.org/doc/api/org/hibernate/id/SequenceHiLoGenerator.html">Sequence-HiLo algorithm</a>.
					</p>
					<p>
						For best performance, HA-JDBC recommends using a high-low or UUID algorithm so that statement parsing and locking costs can be avoided.
						Object-relation mapping (ORM) frameworks (e.g. Hibernate, OJB, Cayanne) typically include implementations of these mechanisms.
					</p>
				</section-->
			</section>
		</section>
		<section>
			<title>Using HA-JDBC</title>
			<section>
				<title>DriverManager-based Access</title>
				<p>
					Just like your database's JDBC driver, the HA-JDBC driver must first be loaded.
					This can be accomplished in one of two ways:
				</p>
				<ul>
					<li>
						<p>Add <code>net.sf.hajdbc.sql.Driver</code> to your <code>jdbc.drivers</code> system property.</p>
						<p>The JVM will automatically load and register each driver upon startup.</p>
					</li>
					<li>
						<p>
							Explicity load the <code>net.sf.hajdbc.sql.Driver</code> class using <code>Class.forName(...)</code>.
						</p>
						<p>
							Per the JDBC specification, loading the HA-JDBC driver class automatically registers the driver with the <code>DriverManager</code>.
							The HA-JDBC driver will automatically load all underlying JDBC drivers defined within a given cluster.
							This means that you do not need to perform an additional <code>Class.forName(...)</code> to load your database's driver.
						</p>
					</li>
				</ul>
				<p>
					The URL specified in subsequent calls to <code>DriverManager.getConnection(...)</code> follow the pattern:
				</p>
				<p><code>jdbc:ha-jdbc:</code><em>cluster-id</em></p>
				<p>e.g.</p>
				<source><![CDATA[
Connection connection = DriverManager.getConnection("jdbc:ha-jdbc:cluster", "postgres", "password");
]]></source>
			</section>
			<section>
				<title>DataSource-based Access</title>
				<p>Use the JNDI name configured in your server configuration to access the HA-JDBC DataSource.</p>
				<p>e.g.</p>
				<source><![CDATA[
Context context = new InitialContext();
DataSource dataSource = (DataSource) context.lookup("java:comp/env/jdbc/Cluster");
Connection connection = dataSource.getConnection("postgres", "password");
]]></source>
			</section>
			<section>
				<title>Advanced JDBC Features</title>
				<section>
					<title>Large Objects</title>
					<p>
						In progress...
					</p>
				</section>
				<section>
					<title>RowSet Implementations</title>
					<p>
						HA-JDBC will work with any RowSet implementation provided that the rowsets are driven by the HA-JDBC driver.
					</p>
					<p>e.g.</p>
					<source><![CDATA[
javax.sql.RowSet rowSet = new com.sun.rowset.CachedRowSetImpl();
rowSet.setCommand("SELECT * FROM TITLES WHERE TYPE = ?");
rowSet.setURL("jdbc:ha-jdbc:cluster");
rowSet.setUsername("postgres");
rowSet.setPassword("password");
rowSet.setString(1, "BIOGRAPHY");
rowSet.execute();
// ...
rowSet.close();
]]></source>
				</section>
			</section>
			<section>
				<title>Failed Database Nodes</title>
				<p>A database node may fail for any number of reasons:</p>
				<ul>
					<li>Network outage</li>
					<li>Hardware failure</li>
					<li>Operating System crash</li>
					<li>Database application crash</li>
					<li>Out of disk space</li>
					<li>No more free connections</li>
					<li>etc.</li>
				</ul>
				<p>
					Failed database nodes are detected after an SQLException is thrown when executing a given database operation.
					A database is determined to have failed if it fails to respond to a trivial query (e.g. SELECT 1).
					The query used to validate that a database is alive is defined by the configured <a href="#dialect">dialect</a>.
				</p>
				<p>If HA-JDBC determines that a given database has failed:</p>
				<ol>
					<li>An ERROR message is logged.</li>
					<li>The database is removed from the internal registry of active databases.  No more requests will be sent to this database.</li>
					<li>If the cluster was configured to be "distributable", other servers are notified of the failure.</li>
				</ol>
				<p>
					Databases may also be manually deactivated via the <a href="#jmx">JMX management interface</a>.
				</p>
			</section>
			<section>
				<title>Restoring a Database Node</title>
				<p>
					Before a database node can be reintroduced into a cluster, may first need to be synchronized.
				</p>
				<p>
					HA-JDBC provides several out-of-the-box database independent strategies for synchronizing a failed database:
				</p>
				<ul>
					<li><a href="api/net/sf/hajdbc/sync/FullSynchronizationStrategy.html"><code>Full</code></a> - Each table in the inactive database is truncated and data is reinserted from an active database.  This strategy is fastest if the database is way out of sync.</li>
					<li><a href="api/net/sf/hajdbc/sync/DifferentialSynchronizationStrategy.html"><code>Differential</code></a> - For each table in the inactive database is compared, row by row, with an active database and only changes are updated.  This strategy is fastest if the database is more in sync than not.</li>
					<li><a href="api/net/sf/hajdbc/sync/PassiveSynchronizationStrategy.html"><code>Passive</code></a> - Does nothing.  Should only be used if databases are known to be in sync.</li>
				</ul>
				<p>
					Each synchronization strategy must be defined in the HA-JDBC configuration file.
					A strategy may contain any number of JavaBean properties that can be set in the config file.
				</p>
				<p>e.g.</p>
				<source><![CDATA[
<ha-jdbc>
  <!-- ... -->
  <sync id="diff" class="net.sf.hajdbc.sync.DifferentialSynchronizationStrategy">
    <property name="fetchSize">1000</property>
  </sync>
  <sync id="full" class="net.sf.hajdbc.sync.FullSynchronizationStrategy">
    <property name="fetchSize">1000</property>
    <property name="maxBatchSize">100</property>
  </sync>
  <sync id="passive" class="net.sf.hajdbc.sync.PassiveSynchronizationStrategy"></sync>
  <!-- ... -->
</ha-jdbc>
]]></source>
				<p>
					Although the build-in strategies should be sufficient for most small databases, they are probably not feasible for large databases.
					Synchronizing a large database will typically require vendor specific functionality.
					Custom synchronization strategies may be written by implementing the <a href="api/net/sf/hajdbc/SynchronizationStrategy.html"><code>SynchronizationStrategy</code></a> interface or by extending the functionality of one of the existing strategies.
					For example, I may want to improve the efficiency of the <code>FullSynchronizationStrategy</code> by dropping and re-creating indexes on my database tables.
				</p>
				<p>e.g.</p>
				<source><![CDATA[
public class FasterFullSynchronizationStrategy extends net.sf.hajdbc.sync.FullSynchronizationStrategy
{
    public void synchronize(Connection inactiveConnection, Connection activeConnection, List tableList)
    {
        // For each table, drop all indexes

        super.synchronize(inactiveConnection, activeConnection, tableList);

        // For each table, recreate all indexes
    }
}
]]></source>
				<p>
					Any custom strategies should also be defined in the configuration file.
				</p>
				<p>
					Database activation is triggered manually via the <a href="#JMX">JMX management interface</a>.
				</p>
			</section>
			<section id="jmx">
				<title>Database Cluster Administration</title>
				<p>
					HA-JDBC database clusters are administered via a JMX management interface: <a href="api/net/sf/hajdbc/DatabaseClusterMBean.html">DatabaseClusterMBean</a>
				</p>
				<p>
					The MBean exposes the following methods:
				</p>
				<ul>
					<li>getId() - Returns the unique identifier of this cluster.</li>
					<li>getActiveDatabases() - Returns a collection of active databases in this cluster.</li>
					<li>getInactiveDatabases() - Returns a collection of inactive databases in this cluster.</li>
					<li>isAlive(String id) - Tests whether the specified database is responding.</li>
					<li>deactivate(String id) - Deactivates the specified database from this cluster.</li>
					<li>activate(String id) - Re-activates the specified database from this cluster using the default synchronization strategy for the database cluster.</li>
					<li>activate(String id, String strategyId) - Re-activates the specified database from this cluster using the specified synchronization strategy.</li>
				</ul>
				<p>
					JMX operations can be executed from the <a href="http://java.sun.com/j2se/1.5.0/docs/guide/management/jconsole.html">JConsole</a> interface packaged with JDK 1.5.
				</p>
				<p>
					As an alternative to JConsole (or for Java 1.4 deployments), many 3rd-party JMX client exist:
				</p>
				<ul>
					<li><a href="http://mc4j.sourceforge.net/">MC4J</a></li>
					<li><a href="http://www.jmanage.org/">jManage</a></li>
					<li><a href="http://ejtools.sourceforge.net/applications/jmx.browser/">EJTools JMX Browser</a></li>
					<li><a href="http://panoptesmgmt.sourceforge.net/">Panoptes</a></li>
					<li><a href="http://www.hta-bi.bfh.ch/Projects/ejbplug/">EJAM - Environment for Java Application Management</a></li>
					<li><a href="http://www.xtremej.com/">XtremeJ Management Suite</a> <em>(Standard Edition single user license is free)</em></li>
				</ul>
				<p>
					HA-JDBC database cluster may also be administered programatically:
				</p>
				<p>e.g.</p>
				<source><![CDATA[
String clusterId = "cluster1";
String databaseId = "database1";

MBeanServer server = (MBeanServer) MBeanServerFactory.findMBeanServer(null).get(0);
ObjectName name = net.sf.hajdbc.DatabaseClusterFactory.getObjectName(clusterId);

// There are 2 ways to programatically invoke methods on an mbean:

// 1. Generic invoke
Object[] parameterValues = new Object[] { databaseId };
String[] parameterTypes = new String[] { databaseId.getClass().getName() };
server.invoke(name, "deactivate", parameterValues, parameterTypes);
server.invoke(name, "activate", parameterValues, parameterTypes);

// 2. Dynamic proxy
Object object = MBeanServerInvocationHandler.newProxyInstance(server, name, DatabaseClusterMBean.class, false);
DatabaseClusterMBean cluster = (DatabaseClusterMBean) object;
cluster.deactivate(databaseId);
cluster.activate(databaseId);
]]></source>
			</section>
		</section>
	</body>
</document>
