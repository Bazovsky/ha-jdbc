<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE document PUBLIC "-//APACHE//DTD Documentation V2.0//EN" "http://forrest.apache.org/dtd/document-v20.dtd">
<document> 
	<header> 
		<title>Documentation</title>
	</header> 
	<body>
		<section>
			<title>Requirements</title>
			<ul>
				<li>
					<p>Java Runtime Environment (1.4 or greater)</p>
				</li>
				<li>
					<p>JDBC 3.0 compliant driver (Type IV recommended)</p>
				</li>
				<li>
					<p>JMX provider (1.2 or greater) e.g.</p>
					<ul>
						<li><a href="http://java.sun.com/products/JavaManagement/index.jsp">Sun Reference Implemenation</a></li>
						<li><a href="http://mx4j.sourceforge.net">MX4J</a></li>
						<li><a href="http://xmojo.sourceforge.net">XMOJO</a></li>
						<li><a href="http://www.jboss.org/developers/projects/jboss/jbossmx">JBossMX</a></li>
						<li><a href="http://www.huihoo.org/jfox/jfoxmx/index.html">JFoxMX</a></li>
					</ul>
				</li>
				<li>
					<p>Exclusive write access to each database in the cluster.</p>
				</li>
				<li>
					<p>All databases in cluster must initially be in sync.</p>
				</li>
			</ul>
		</section>
		<section>
			<title>Configuration</title>
			<section>
				<title>Database Cluster Configuration</title>
				<p>
					Configuration for HA-JDBC managed database clusters is contained in a single XML file.
					The format of the configuration file should match the DTD: <a href="http://ha-jdbc.sourceforge.net/dtd/ha-jdbc-1.0.dtd"><code>http://ha-jdbc.sourceforge.net/dtd/ha-jdbc-1.0.dtd</code></a>
				</p>
				<p>Sample configuration file containing each type of deployment setup:</p>
				<source><![CDATA[
<?xml version="1.0"?>
<!DOCTYPE ha-jdbc PUBLIC "-//HA-JDBC//DTD HA-JDBC 1.0//EN"
  "http://ha-jdbc.sourceforge.net/dtd/ha-jdbc-1.0.dtd">
<ha-jdbc>
  <cluster name="cluster">
    <database url="jdbc:postgresql://server1:5432/database" driver="org.postgresql.Driver">
      <user>postgres</user>
      <password>password</password>
    </database>
    <database url="jdbc:postgresql://server2:5432/database" driver="org.postgresql.Driver">
      <user>postgres</user>
      <password>password</password>
    </database>
  </cluster>
  <cluster name="Cluster">
    <datasource name="java:comp/env/jdbc/Database1"></datasource>
    <datasource name="java:comp/env/jdbc/Database2"></datasource>
  </cluster>
  <cluster name="PoolCluster">
    <pool-datasource name="java:comp/env/jdbc/pool/Database1"></pool-datasource>
    <pool-datasource name="java:comp/env/jdbc/pool/Database2"></pool-datasource>
  </cluster>
  <cluster name="XACluster">
    <xa-datasource name="java:comp/env/jdbc/xa/Database1"></xa-datasource>
    <xa-datasource name="java:comp/env/jdbc/xa/Database2"></xa-datasource>
  </cluster>
</ha-jdbc>
]]></source>
				<p>
					The algorithm used to locate the configuration file resource at runtime is as follows:
				</p>
				<ol>
					<li>
						<p>Read the resource name from the <code>ha-jdbc.configuration</code> system property.  If not defined, the default value "<code>ha-jdbc.xml</code>" is used.</p>
					</li>
					<li>
						<p>Attempt to interpret the resource name as a URL.</p>
					</li>
					<li>
						<p>If the resource name cannot be converted to a URL, then search for the resource in the classpath using the following algorithm:</p>
						<ol>
							<li>Search for resource using the thread context class loader.</li>
							<li>If not found, search for resource using the class loader of the current class.</li>
							<li>If not found, search for resource using the system class loader.</li>
						</ol>
					</li>
					<li>
						<p>If still not found, throw an exception back to the caller.</p>
					</li>
				</ol>
			</section>
			<section>
				<title>Application Configuration</title>
				<section>
					<title>Server configuration examples</title>
					<ul>
						<li>
							<p><a href="http://jetty.mortbay.org">Jetty</a> (using <a href="http://xapool.objectweb.org">XAPool</a>)</p>
							<source><![CDATA[
<Configure class="org.mortbay.jetty.plus.Server">
  <Call name="addService">
    <Arg>
      <New class="org.mortbay.jetty.plus.DefaultDataSourceService">
        <Set name="Name">DataSourceService</Set>
        <Call name="addConnectionPoolDataSource">
          <Arg>jdbc/Cluster</Arg>
          <Arg>
            <New class="org.enhydra.jdbc.standard.StandardConnectionPoolDataSource">
              <Set name="DriverName">net.sf.hajdbc.Driver</Set>
              <Set name="Url">jdbc:ha-jdbc:cluster</Set>
              <Set name="TransactionIsolation">
                <Get class="java.sql.Connection" name="TRANSACTION_READ_COMMITTED"/>
              </Set>
            </New>
          </Arg>
          <Set name="User">postgres</Set>
          <Set name="Password">password</Set>
          <Set name="MinSize">5</Set>
          <Set name="MaxSize">50</Set>
          <Set name="CheckLevelObject">2</Set>
          <Set name="JdbcTestStmt">SELECT 1</Set>
        </Call>
      </New>
    </Arg>
  </Call>
</Configure>
]]></source>
						</li>
						<li>
							<p><a href="http://jakarta.apache.org/tomcat">Tomcat</a> (using <a href="http://jakarta.apache.org/commons/dbcp">DBCP</a>)</p>
							<source><![CDATA[
<Resource name="jdbc/Cluster" auth="Container" type="javax.sql.DataSource"/>
<ResourceParams name="jdbc/Cluster">
  <parameter>
    <name>factory</name>
    <value>org.apache.commons.dbcp.BasicDataSourceFactory</value>
  </parameter>
  <parameter>
    <name>maxActive</name>
    <value>100</value>
  </parameter>
  <parameter>
    <name>maxWait</name>
    <value>10000</value>
  </parameter>
  <parameter>
    <name>username</name>
    <value>postgres</value>
  </parameter>
  <parameter>
    <name>password</name>
    <value>password</value>
  </parameter>
  <parameter>
    <name>driverClassName</name>
    <value>net.sf.hajdbc.Driver</value>
  </parameter>
  <parameter>
    <name>url</name>
    <value>jdbc:ha-jdbc:cluster</value>
  </parameter>
</ResourceParams>
]]></source>
						</li>
						<li>
							<p>More server configuration examples coming soon...</p>
						</li>
					</ul>
				</section>
			</section>
			<section>
				<title>Distributed environment</title>
				<p>
					When running HA-JDBC in a distributed environment, i.e. JDBC clients in seperate JVMs are accessing the same set of databases, special configuration is required.
					HA-JDBC leverages the <a href="http://www.jgroups.org">JGroups</a> project to handle communication between cluster managers.
					See the JGroup User's guide for assistance customizing the protocol stack for your network.
				</p>
				<p>e.g.</p>
				<source><![CDATA[
<ha-jdbc>
  <distributable protocol="UDP(mcast_addr=228.10.9.8;mcast_port=5678):PING:FD:GMS"/>
  <cluster name="...">
    <!-- ... -->
  </cluster>
</ha-jdbc>
]]></source>
			</section>
			<section>
				<title>Unique identifier generation</title>
				<p>The following traditional mechanisms for generating unique identifiers are problematic for clustered database environments:</p>
				<ul>
					<li>Identity columns (supported by MySQL, HSQLDB, DB2, MS SQL Server, Sybase, etc.) fetched using the Java 1.4 <code>ResultSet.getGeneratedKeys()</code> method</li>
					<li>Sequences (supported by PostgreSQL, MySQL MaxDB (fka SAP DB), Firebird (fka Interbase), Mckoi, Oracle, DB2, etc.)</li>
				</ul>
				<p>
					For any of these mechanisms to work in a database cluster, each database node would need to independently generate the same identifiers.
					To make this happen, all incoming database requests would need to be synchronized through a central cluster manager.
					This would adversely affect the scalability of the cluster as the number of distributed clients increase.
					For now, HA-JDBC does not accommodate the above mechanisms in favor a design that uses more efficient asynchronous request execution.
				</p>
				<p>The following alternative unique identifier generation methods will work properly with HA-JDBC:</p>
				<ul>
					<li>High-Low algorithm (often implemented using a Stateless Session EJB)</li>
					<li>UUID algorithms</li>
					<li>Others?</li>
				</ul>
				<p>
					Most object-relation mapping (ORM) frameworks (e.g. JDO, Hibernate, OJB, Cayanne) include implementations of these mechanisms.
					ORM frameworks will even recommend these mechanisms over sequences and identity columns for the sake of portability.
				</p>
			</section>
			<section>
				<title>Transactions</title>
				<p>
					HA-JDBC supports both traditional JDBC transactions and JTA.
					HA-JDBC integration will not require you to change your existing transaction semantics.
					If you are leveraging your JDBC driver's <code>javax.sql.XADataSource</code> implementation for JTA integration, you will need to configure HA-JDBC accordingly.
				</p>
				<p>e.g.</p>
				<source><![CDATA[
<cluster name="Cluster">
  <xa-datasource name="java:comp/env/jdbc/xa/DataSource1">
    <user>postgres</user>
    <password>password</password>
  </xa-datasource>
  <xa-datasource name="java:comp/env/jdbc/xa/DataSource2">
    <user>postgres</user>
    <password>password</password>
  </xa-datasource>
</cluster>
]]></source>
			</section>
			<section>
				<title>Connection Pooling</title>
				<p>
					HA-JDBC is designed to integrate with your existing connection pooling mechanism.
					If you are leveraging your JDBC driver's <code>javax.sql.ConnectionPoolDataSource</code> implementation for connection pooling, you will need to configure HA-JDBC accordingly.
				</p>
				<p>e.g.</p>
				<source><![CDATA[
<cluster name="Cluster">
  <pool-datasource name="java:comp/env/jdbc/pool/DataSource1">
    <user>postgres</user>
    <password>password</password>
  </pool-datasource>
  <pool-datasource name="java:comp/env/jdbc/pool/DataSource2">
    <user>postgres</user>
    <password>password</password>
  </pool-datasource>
</cluster>
]]></source>
			</section>
		</section>
		<section>
			<title>Using HA-JDBC</title>
			<section>
				<title>DriverManager-based Access</title>
				<p>
					Just like your database's JDBC driver, the HA-JDBC driver must first be loaded.
					This can be accomplished in one of two ways:
				</p>
				<ul>
					<li>
						<p>Add <code>net.sf.hajdbc.Driver</code> to your <code>jdbc.drivers</code> system property.</p>
						<p>The JVM will automatically load and register each driver upon startup.</p>
					</li>
					<li>
						<p>
							Explicity load the <code>net.sf.hajdbc.Driver</code> class using <code>Class.forName(...)</code>.
						</p>
						<p>
							Per the JDBC specification, loading the HA-JDBC driver class automatically registers the driver with the <code>DriverManager</code>.
							The HA-JDBC driver will automatically load all underlying JDBC drivers defined within a given cluster.
							This means that you do not need to perform an additional <code>Class.forName(...)</code> to load your database's driver.
						</p>
					</li>
				</ul>
				<p>
					The URL to use in subsequent calls to <code>DriverManager.connect(...)</code> should use the name of your cluster.
					Database clusters will be named using the following convention:
				</p>
				<p><code>jdbc:ha-jdbc:</code><em>cluster-name</em></p>
				<p>e.g.</p>
				<source><![CDATA[
Connection connection = DriverManager.connect("jdbc:ha-jdbc:cluster", "postgres", "password");
]]></source>
			</section>
			<section>
				<title>DataSource-based Access</title>
				<p>Use the JNDI name configured in your server configuration to access the HA-JDBC DataSource.</p>
				<p>e.g.</p>
				<source><![CDATA[
Context context = new InitialContext();
DataSource dataSource = (DataSource) context.lookup("java:comp/env/jdbc/Cluster");
Connection connection = dataSource.getConnection("postgres", "password");
]]></source>
			</section>
			<section>
				<title>Advanced JDBC Features</title>
				<section>
					<title>Large Objects</title>
					<p>
						In progress...
					</p>
				</section>
				<section>
					<title>JSR 114 RowSets</title>
					<p>
						HA-JDBC will work with any JSR 114 implementation provided that the rowsets are driven via the HA-JDBC driver.
					</p>
					<p>e.g.</p>
					<source><![CDATA[
com.sun.rowset.CachedRowSetImpl rs = new com.sun.rowset.CachedRowSetImpl();
rs.setCommand("SELECT * FROM TITLES WHERE TYPE = ?");
rs.setURL("jdbc:ha-jdbc:cluster");
rs.setUsername("postgres");
rs.setPassword("password");
rs.setString(1, "BIOGRAPHY");
rs.execute();
// ...
rs.close();
]]></source>
				</section>
			</section>
			<section>
				<title>Failed Database Nodes</title>
				<p>A database node may fail for any number of reasons:</p>
				<ul>
					<li>Hardware failure</li>
					<li>Operating System crash</li>
					<li>Database application crash</li>
					<li>Out of disk space</li>
					<li>No more free connections</li>
					<li>etc.</li>
				</ul>
				<p>
					Failed database nodes are detected after an SQLException is thrown when executing a given database operation.
					A database is determined to have failed if it fails to respond to a trivial query (e.g. SELECT 1).
					The query used to validate that a database is responding can be configured via the HA-JDBC configuration file.
				</p>
				<p>e.g.</p>
				<source><![CDATA[
<ha-jdbc>
	<cluster name="cluster">
		<!-- Sample validation query for HSQLDB -->
		<validate-sql>CALL NOW()</validate-sql>
		<database url="..." driver="..."></database>
		<database url="..." driver="..."></database>
	</cluster>
</ha-jdbc>
]]></source>
				<p>If HA-JDBC determines that a given database has failed:</p>
				<ol>
					<li>An ERROR message is logged.</li>
					<li>The database is removed from the internal registry of active databases.  No more requests will be sent to this database.</li>
					<li>If the cluster was configured to be "distributable", other servers are notified of the failure.</li>
				</ol>
				<p>
					Databases may also be manually deactivated via the <a href="#JMX">JMX management interface</a>.
				</p>
			</section>
			<section>
				<title>Restoring a Database Node</title>
				<p>
					Before a database node can be reintroduced into a cluster, it first must be synchronized.
				</p>
				<p>
					HA-JDBC provides several out-of-the-box database independent strategies for synchronizing a failed database:
				</p>
				<ul>
					<li><a href="api/net/sf/hajdbc/sync/FullSynchronizationStrategy.html"><code>Full</code></a> - Each tables is truncated and data is reinserted.  This strategy is fastest if the database is way out of sync.</li>
					<li><a href="api/net/sf/hajdbc/sync/DifferentialSynchronizationStrategy.html"><code>Differential</code></a> - Comparison is done on each table and only changes are updated.  This strategy is fastest if the database is only slightly out of sync.</li>
					<li><a href="api/net/sf/hajdbc/sync/PassiveSynchronizationStrategy.html"><code>Passive</code></a> - Does nothing.  Should only be used when database are already in sync.</li>
				</ul>
				<p>
					Although these mechanisms should be sufficient for most small databases, they are probably not feasible for large databases.
					Synchronizing a large database will require vendor specific functionality.
					Custom synchronization strategies may be written by implementing the <a href="api/net/sf/hajdbc/SynchronizationStrategy.html"><code>SynchronizationStrategy</code></a> interface or by extending the functionality of one of the existing strategies.
					For example, I may want to improve the efficiency of the <code>FullSynchronizationStrategy</code> by dropping and re-creating indexes on my database tables.
				</p>
				<p>e.g.</p>
				<source><![CDATA[
public class FasterFullSynchronizationStrategy extends FullSynchronizationStrategy
{
    public void synchronize(Connection inactiveConnection,
                            Connection activeConnection,
                            List tableList,
                            DatabaseClusterDescriptor descriptor)
    {
        // For each table, drop all indexes

        super.synchronize(inactiveConnection, activeConnection, tableList, descriptor);

        // For each table, recreate all indexes
    }
}
]]></source>
				<p>
					The default synchronization strategy is configured in the HA-JDBC configuration file.
				</p>
				<p>e.g.</p>
				<source><![CDATA[
<ha-jdbc>
	<cluster name="cluster">
		<default-sync-strategy>net.sf.hajdbc.sync.FullSynchronizationStrategy</default-sync-strategy>
		<database url="..." driver="..."></database>
		<database url="..." driver="..."></database>
	</cluster>
</ha-jdbc>
]]></source>
				<p>
					Database activation is triggered manually via the <a href="#JMX">JMX management interface</a>.
				</p>
			</section>
			<section id="JMX">
				<title>Database Cluster Administration</title>
				<p>
					HA-JDBC database clusters are administered via a JMX management interface: <a href="api/net.sf.hajdbc.DatabaseClusterMBean">DatabaseClusterMBean</a>
				</p>
				<p>
					The MBean exposes the following methods:
				</p>
				<ul>
					<li>getName() - Returns the name of this cluster.</li>
					<li>getActiveDatabaseList() - Returns a list of active databases for this cluster.</li>
					<li>isAlive(String id) - Test whether the specified database is responding.</li>
					<li>deactivate(String id) - Deactivates the specified database from this cluster.</li>
					<li>activate(String id) - Re-activates the specified database using the default synchronization strategy.</li>
					<li>activate(String id, String strategyClassName) - Deactivates the specified database from this cluster using the specified synchronization strategy.</li>
				</ul>
				<p>3rd-party JMX clients provide easy graphical interfaces for managing HA-JDBC clusters:</p>
				<ul>
					<li><a href="http://mc4j.sourceforge.net/">MC4J</a></li>
					<li><a href="http://ejtools.sourceforge.net/applications/jmx.browser/">EJTools JMX Browser</a></li>
					<li><a href="http://panoptesmgmt.sourceforge.net/">Panoptes</a></li>
					<li><a href="http://jmxview.sourceforge.net/">JMXView</a></li>
					<li><a href="http://www.xtremej.com/">XtremeJ Management Suite</a> (Standard Edition single user license is free)</li>
				</ul>
				<p>HA-JDBC database cluster may also be administered programatically:</p>
				<p>e.g.</p>
				<source><![CDATA[
MBeanServer server = (MBeanServer) MBeanServerFactory.findMBeanServer(null).get(0);
ObjectName name = ObjectName.getInstance("net.sf.hajdbc", "cluster", ObjectName.quote("jdbc:ha-jdbc:cluster"));
String database = "jdbc:postgresql://server2:5432/database";

// There are 2 ways to invoke methods on an mbean:

// 1. Generic invoke
server.invoke(name, "deactivate", new Object[] { database }, new String[] { "java.lang.String" });
server.invoke(name, "activate", new Object[] { database }, new String[] { "java.lang.String" });

// 2. Dynamic proxy
Object object = MBeanServerInvocationHandler.newProxyInstance(server, name, DatabaseClusterMBean.class, false);
DatabaseClusterMBean cluster = (DatabaseClusterMBean) object;
cluster.deactivate(database);
cluster.activate(database);
]]></source>
			</section>
		</section>
	</body>
</document>
