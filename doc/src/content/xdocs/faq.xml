<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE faqs PUBLIC "-//APACHE//DTD FAQ V2.0//EN" "http://xml.apache.org/forrest/dtd/faq-v20.dtd">
<faqs>
	<title>Frequently Asked Questions</title>
	<faqsection>
		<title>Dependency FAQs</title>
		<faq>
			<question>JGroups FAQ</question>
			<answer><a href="http://www.jgroups.org/javagroupsnew/docs/faq.html">http://www.jgroups.org/javagroupsnew/docs/faq.html</a></answer>
		</faq>
		<faq>
			<question>SLF4J FAQ</question>
			<answer><a href="http://slf4j.org/faq.html">http://slf4j.org/faq.html</a></answer>
		</faq>
		<faq>
			<question>Quartz FAQ</question>
			<answer><a href="http://www.opensymphony.com/quartz/wikidocs/FAQ.htmll">http://www.opensymphony.com/quartz/wikidocs/FAQ.html</a></answer>
		</faq>
	</faqsection>
	<faqsection>
		<title>Configuring HA-JDBC</title>
		<faq>
			<question>How do I configure HA-JDBC to notify me when a database is deactivated?</question>
			<answer>
				Use your logging facility.  HA-JDBC generates an ERROR level log message when it automatically deactivates a database.
				If you use Log4J, configure an SMTP appender for the "net.sf.hajdbc" logger.<br/>
				If you use java.util.logging, configure an <a href="http://http://smtphandler.sourceforge.net/">SMTPHandler</a> for the "net.sf.hajdbc" package.
			</answer>
		</faq>
		<faq>
			<question>I need to pass additional parameters to my JDBC driver.  How can I specify these in my HA-JDBC configuration?</question>
			<answer>
				<p>
					The <code>database</code> element may contain any number of <code>property</code> elements.
					HA-JDBC will pass these properties through to the Driver.connect(String url, Properties info) method of the underlying JDBC driver.
				</p>
				<p>e.g.</p>
				<source><![CDATA[
<cluster id="..." balancer="..." default-sync="...">
  <database id="...">
    <driver>org.postgresql.Driver</driver>
    <url>jdbc:postgresql:database</url>
    <property name="ssl">true</property>
    <user>postgres</user>
    <password>XXXX</password>
  </database>
</cluster>
]]></source>
				<p>
				</p>
				<p>
					Alternatively, many JDBC drivers accept properties appended directly to the url.
				</p>
				<p>e.g.</p>
				<source><![CDATA[
<cluster id="..." balancer="..." default-sync="...">
  <database id="...">
    <driver>org.postgresql.Driver</driver>
    <url>jdbc:postgresql:database?ssl=true</url>
    <user>postgres</user>
    <password>XXXX</password>
  </database>
</cluster>
]]></source>
			</answer>
		</faq>
		<faq>
			<question>How can I specify JNDI environment properties to my HA-JDBC DataSource configuration?</question>
			<answer>
				<p>
					The <code>datasource</code> element may contain any number of <code>property</code> elements.
					HA-JDBC will pass these properties into the InitialContext(Hashtable env) constructor.
				</p>
				<p>e.g.</p>
				<source><![CDATA[
<cluster id="..." balancer="..." default-sync="...">
  <datasource id="...">
    <name>jdbc/database</name>
    <property name="java.naming.factory.initial">org.jnp.interfaces.NamingContextFactory</property>
    <property name="java.naming.factory.url.pkgs">org.jboss.naming:org.jnp.interfaces</property>
  </datasource>
</cluster>
]]></source>
				<p>
					Alternatively, these properties may be specified in an jndi.properties application resource file.
					Details <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/naming/InitialContext.html">here</a>.
				</p>
			</answer>
		</faq>
	</faqsection>
	<faqsection>
		<title>Using HA-JDBC</title>
		<faq>
			<question>I get a java.lang.OutOfMemoryError when synchronizing a failed cluster node.  Why?</question>
			<answer>
				<p>
					This can occur if your database contains a table with more rows than can be fetched into memory at once.
					Both the differential and full synchronization strategies have a <code>fetchSize</code> property that control the number of rows that are fetched at a time.
				</p>
				<p>e.g.</p>
<source><![CDATA[
<sync id="diff" class="net.sf.hajdbc.sync.DifferentialSynchronizationStrategy">
  <property name="fetchSize">1000</property>
</sync>
]]></source>
				<p>
					Each strategy also has a <code>maxBatchSize</code> property to control the number of statements to execute at a time.
				</p>
				<p>e.g.</p>
<source><![CDATA[
<sync id="full" class="net.sf.hajdbc.sync.FullSynchronizationStrategy">
  <property name="maxBatchSize">50</property>
</sync>
]]></source>
			</answer>
		</faq>
		<faq>
			<question>How can HA-JDBC be leveraged to improve database-driven HTTP Session failover?</question>
			<answer>
				<p>
					Several session replication methods are described in an <a href="http://www.theserverside.com/articles/article.tss?l=J2EEClustering">article</a> posted to TheServerSide.com.
					Figure 7 illustrates the database persistence approach.
					When describing the disadvantages of this approach, the article fails to mention that the session database is a single point of failure in this design.
					HTTP sessions will survive the failure of an application server node, but failure of the session database spells doom for the application.
				</p>
				<p>
					However, this can easily remedied with redundant session databases using the HA-JDBC driver in distributable mode.
				</p>
				<p>e.g.</p>
				<p>
					For Tomcat, following the configuration instructions for setting up a Persistent Manager using a JDBC store <a href="http://jakarta.apache.org/tomcat/tomcat-5.0-doc/config/manager.html">here</a>.
					Simply use HA-JDBC's driver and url in place of your database's JDBC driver and url for the <code>driverName</code> and <code>connectionURL</code> properties of your store configuration.
				</p>
			</answer>
		</faq>
		<faq>
			<question>Can I use HA-JDBC with Tomcat 5.0?</question>
			<answer>
				Yes, but first you will need to upgrade the JMX implementation used by Tomcat (found in $CATALINA_HOME/bin/jmx.jar).
				Tomcat 5.0 ships with MX4J 1.1.1 which only implements JMX 1.1.
				Because HA-JDBC requires JMX 1.2, you will need to upgrade this file to MX4J 2.0 or greater.
			</answer>
		</faq>
		<faq>
			<question>HA-JDBC remembers which databases were inactive even after I restart my JVM.  Where is this state recorded and how do I clear it?</question>
			<answer>
				<p>
					HA-JDBC uses the Java preferences API to persist the local database cluster state.
					The default storage mechanism varies depending on your operating system.
				</p>
				<p>On Unix-like systems, the cluster state will be stored on the file system within the user's home directory:</p>
				<p><code>~/.java/.userPrefs/net/sf/hajdbc/local/prefs.xml</code></p>
				<p>On Windows systems, the cluster state will be stored in the registry:</p>
				<p><code>HKEY_CURRENT_USER\Software\JavaSoft\Prefs\net\sf\hajdbc\local\</code><em>cluster-name</em></p>
			</answer>
		</faq>
		<faq>
			<question>
				Why does my application need to specify a username and password when making database connections through HA-JDBC when the necessary authentication information is already specified in its configuration file?
			</question>
			<answer>
				<p>
					The username and password set in the configuration file are only used by HA-JDBC when it needs to connect to a database independently of your application.  e.g. during synchronization, DatabaseCluster.isAlive() calls, etc.
					When your application connects to the database, the authentication information specified is passed through to the underlying driver.
				</p>
				<p>
					The purpose of this authentication pass-through is to retain the flexibility your application had without HA-JDBC to use an appropriate database user (with an appropriate set of permissions) for a given task.
					Traditionally, applications will use a database user with select/insert/update/delete privileges only.
					Some application may not need to write information to a database and can use a database user with select privileges only.
					The database user that is used by HA-JDBC should be more of a root/superuser, with specific abilities to drop and create indexes and foreign keys (used during synchronization).
				</p>
				<p>
					Since the same password will be passed through to each database, the user used by your application must exist and have the same password on each database in your cluster.
					The usernames/passwords used by HA-JDBC (as specified in the configuration file), however, do not need to be the same on each database.
				</p>
			</answer>
		</faq>
		<faq>
			<question>Using version 1.4 or 1.5 of Sun's Java implementation, HA-JDBC mysteriously deadlocks the first time DriverManager.getConnection() is called.  Why?</question>
			<answer>
				<p>
					In Java 1.5 and earlier, all of the methods on <code>java.sql.DriverManager</code> are synchronized.
					Your initial call to <code>DriverManager.getConnection(...)</code> triggers the startup of HA-JDBC.
					As HA-JDBC initializes, it will eventually call <code>DriverManager.getDriver(...)</code> for each database url in your cluster.
					The calls to <code>DriverManager.getDriver(...)</code> occur in a different thread from your application thread, hence the deadlock.
				</p>
				<p>There are at least 2 known workarounds for this problem:</p>
				<ol>
					<li>
						Upgrade to Java 1.6.
						After forever insisting that the blanket synchronization of <code>java.sql.DriverManager</code> was <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4263113">not a defect</a>, Sun <em>silently</em> fixed this in Java 1.6.
					</li>
					<li>
						Rather than use <code>DriverManager.getConnection(...)</code> to obtain connections, use <code>DriverManager.getDriver(...).connect(...)</code> instead.
						This will circumvent the deadlock since DriverManager.getDriver(...) will not trigger HA-JDBC startup and Driver.connect(...) is not synchronized.
					</li>
				</ol>
			</answer>
		</faq>
	</faqsection>
	<faqsection>
		<title>About HA-JDBC</title>
		<faq>
			<question>How does HA-JDBC compare to <a href="http://http://sequoia.continuent.org">Sequoia</a>?</question>
			<answer>
				<p>
					Both HA-JDBC and Sequoia attempt to solve the same problem (i.e. eliminating the database as a single point of failure), but have different approaches.
				</p>
				<table>
					<caption>Feature comparison</caption>
					<tr>
						<th></th>
						<th>HA-JDBC</th>
						<th>Sequoia</th>
					</tr>
					<tr>
						<th>Architecture</th>
						<td>
							<ol>
								<li>HA-JDBC driver delegates JDBC methods directly to the underlying JDBC drivers.</li>
								<li>Cluster details are stored in distributed cache on client.</li>
								<li>Leverages underlying database for request scheduling.</li>
								<li>High-availability is inherent in symmetric design.</li>
							</ol>
						</td>
						<td>
							<ol>
								<li>Sequoia's JDBC driver delegates query execution to a remote controller process.  Controller then delegates queries to the underlying JDBC driver.</li>
								<li>Cluster details are known only to controller.</li>
								<li>The controller's request scheduler strategy is responsible for determining execution order.</li>
								<li>Controller introduces new single point-of-failure.  Workaround is to set up a failover controller process.  Details <a href="http://c-jdbc.objectweb.org/current/doc/C-JDBC_horizontal_scalability.pdf">here</a>.</li>
							</ol>
						</td>
					</tr>
					<tr>
						<th>Cluster topography</th>
						<td>
							<ol>
								<li>Databases within a cluster must be homogenous.</li>
								<li>Supports "mirroring" only.</li>
							</ol>
						</td>
						<td>
							<ol>
								<li>Supports heterogenous database clusters - requires that SQL queries be translated to appropriate SQL dialect.</li>
								<li>Supports RAIDb-0, RAIDb-1, and RAIDb-2 configurations (i.e. mirroring (replication), striping (partitioning), and partial mirroring/striping, respectively).</li>
							</ol>
						</td>
					</tr>
					<tr>
						<th>Failed node recovery</th>
						<td>
							<ol>
								<li>No recovery log is maintained.</li>
								<li>Synchronization achieved through various brute force strategies.</li>
								<li>Inefficient hot synchronization capability tolerated at the savings of performance during normal usage.</li>
								<li>Includes the ability to automatically reactivate failed database nodes according to a schedule.</li>
							</ol>
						</td>
						<td>
							<ol>
								<li>Controller uses internal database recovery log to restore state of a reactivated database.</li>
								<li>Synchronization is done by executing SQL statements since last checkpoint.</li>
								<li>Efficient hot synchronization capability achieved at the cost of recovery log overhead.</li>
								<li>Failed database nodes can only be re-activated manually.</li>
							</ol>
						</td>
					</tr>
					<tr>
						<th>Performance</th>
						<td>
							<p>
								Faster reads under load, slightly slower writes than standard JDBC.
								Details <a href="performance.html">here</a>.
							</p>
						</td>
						<td>
							<p>
								Qualitatively slower than HA-JDBC since each request requires an additional network hop (i.e. driver to controller, controller to database).
								Details <a href="http://c-jdbc.objectweb.org/current/doc/RR-C-JDBC.pdf">here</a>.
							</p>
						</td>
					</tr>
					<tr>
						<th>Cluster administration</th>
						<td>
							<p>Leverages JConsole from Sun's JDK 1.5+ or any other 3rd party JMX console for cluster administration.</p>
						</td>
						<td>
							<p>Provides custom JMX-based command-line administration console.</p>
						</td>
					</tr>
					<tr>
						<th>Provides connection pooling</th>
						<td>
							<p>
								No - many open source solutions already exist and can be used in conjunction with HA-JDBC:
							</p>
							<ul>
								<li><a href="http://c3p0.sourceforge.net">c3p0</a></li>
								<li><a href="http://proxool.sourceforge.net">Proxool</a></li>
								<li><a href="http://jakarta.apache.org/commons/dbcp">Commons DBCP</a></li>
								<li><a href="http://xapool.objectweb.org">XAPool</a></li>
								<li><a href="http://www.primrose.org.uk">Primrose</a></li>
							</ul>
						</td>
						<td>
							<p>Yes - implemented in controller</p>
						</td>
					</tr>
					<tr>
						<th>ResultSet caching ability</th>
						<td>
							<p>
								No - Transparent result set caching is available through <a href="http://www.irongrid.com/catalog/product_info.php?products_id=31">IronEye Cache</a>.
							</p>
						</td>
						<td>
							<p>Yes - implemented in controller</p>
						</td>
					</tr>
					<tr>
						<th>JDBC 2.0 feature support</th>
						<td>
							<p>Full support</p>
						</td>
						<td>
							<p>
								Lacks support for:
							</p>
							<ul>
								<li>Database-compiled <code>PreparedStatement</code>s</li>
								<li><code>CallableStatement</code>s with OUT parameters</li>
								<li>True large object support - Blob and Clob are simulated with encoded <code>byte[]</code> and <code>String</code>, respectively</li>
								<li>True binary/character stream support - simulated with encoded <code>byte[]</code> and <code>String</code>, respectively</li>
								<li>Array and Ref types</li>
								<li>Custom type mapping</li>
								<li>Block fetched scrollable <code>ResultSet</code>s</li>
								<li><code>Statement</code> execution cancellation</li>
							</ul>
						</td>
					</tr>
					<tr>
						<th>JDBC 3.0 support</th>
						<td>
							<p>Full support</p>
						</td>
						<td>
							<p>
								Lacks support for:
							</p>
							<ul>
								<li>Transactional <code>Savepoint</code>s</li>
								<li><code>XADataSource</code> and <code>XAConnection</code></li>
								<li><code>PreparedStatement</code> pooling</li>
								<li>Retrieval of auto-generated keys</li>
								<li><code>ParameterMetaData</code></li>
								<li><code>ResultSet</code> holdability support</li>
								<li>Queries/Store procedures that return multiple <code>ResultSet</code>s</li>
								<li>Updatable Blobs and Clobs</li>
							</ul>
						</td>
					</tr>
					<tr>
						<th>JDBC 4.0 support</th>
						<td>
							<p>Full support</p>
						</td>
						<td>
							<p>None</p>
						</td>
					</tr>
				</table>
			</answer>
		</faq>
	</faqsection>
</faqs>
