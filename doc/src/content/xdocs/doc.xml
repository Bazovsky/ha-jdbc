<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE document PUBLIC "-//APACHE//DTD Documentation V2.0//EN" "http://forrest.apache.org/dtd/document-v20.dtd">
<document>
	<header> 
		<title>Documentation</title>
	</header>
	<body>
		<section>
			<title>Requirements</title>
			<ul>
				<li>Java Runtime Environment 1.5 (Java 1.4 supported via Retrotranslator)<a href="#Java1.4">*</a></li>
				<li>Type IV <acronym title="Java Database Connectivity">JDBC</acronym> 3.0 compliant driver</li>
				<li>An MBean server<a href="#MBeanServer">*</a></li>
				<li>All databases in a cluster must initially be in sync.</li>
			</ul>
			<section id="Java1.4">
				<title>Using Java 1.4</title>
				<p>
					As of version 1.1, HA-JDBC ships 2 binary distributions.  The default binary requires Java 1.5.
					A Java 1.4 compatible binary is generated using <a href="http://retrotranslator.sourceforge.net">Retrotranslator</a>.
					Consequently, this binary has some additional runtime dependencies, contained in the <code>/lib/runtime-1.4</code> directory of the distribution.
				</p>
				<p>
					HA-JDBC requires a <acronym title="Java Management Extensions">JMX</acronym> 1.2+ MBean server.
					While Java 1.5 includes Sun's <acronym title="Java Management Extensions">JMX</acronym> reference implementation, Java 1.4 does not.
					Therefore, if your application server or servlet container does not include a <acronym title="Java Management Extensions">JMX</acronym> 1.2 implementation, it is up to you to supply one.
					Below is a list of popular and free <acronym title="Java Management Extensions">JMX</acronym> implementations available to you:
				</p>
				<ul>
					<li><a href="http://java.sun.com/products/JavaManagement/index.jsp">Sun's <acronym title="Java Management Extensions">JMX</acronym> Reference Implemenation</a></li>
					<li><a href="http://mx4j.sourceforge.net">MX4J</a></li>
					<li><a href="http://www.xmojo.org/products/xmojo">XMOJO</a></li>
					<li><a href="http://www.jboss.org/developers/projects/jboss/jbossmx">JBossMX</a></li>
					<li><a href="http://www.huihoo.org/jfox/jfoxmx/index.html">JFoxMX</a></li>
				</ul>
			</section>
			<section id="MBeanServer">
				<title>Creating an MBean server</title>
				<p>
					If you are using HA-JDBC outside a servlet/<acronym title="Enterprise Java Bean">EJB</acronym> container, or if you are supplying your own <acronym title="Java Management Extensions">JMX</acronym> implementation, you may need to explicitly create an MBean server.
					If this is the case, add the following code to a startup hook in your application:
				</p>
				<source>javax.management.MBeanServerFactory.createMBeanServer();</source>
			</section>
		</section>
		<section>
			<title>Configuration</title>
			<p>
				Configuration for HA-JDBC managed database clusters is contained in a single XML file.
				The algorithm used to locate the configuration file resource at runtime is as follows:
			</p>
			<ol>
				<li>
					<p>Read the resource name from the <code>ha-jdbc.configuration</code> system property.  If not defined, the default value "<code>ha-jdbc.xml</code>" is used.</p>
				</li>
				<li>
					<p>Attempt to interpret the resource name as a URL.</p>
				</li>
				<li>
					<p>If the resource name cannot be converted to a URL, then search for the resource in the classpath using the following algorithm:</p>
					<ol>
						<li>Search for resource using the thread context class loader.</li>
						<li>If not found, search for resource using the class loader of the current class.</li>
						<li>If not found, search for resource using the system class loader.</li>
					</ol>
				</li>
				<li>
					<p>If still not found, throw an exception back to the caller.</p>
				</li>
			</ol>
			<p>
				The root element of the configuration file has the following definition:
			</p>
			<source id="ha-jdbc">&lt;!ELEMENT ha-jdbc (<a href="#distributable">distributable</a>?,<a href="#sync">sync</a>+,<a href="#cluster">cluster</a>+)&gt;</source>
			<section id="distributable">
				<title>distributable</title>
				<p>
					Indicates that database clusters defined in this file will be accessed by multiple JVMs.
					HA-JDBC leverages the <a href="http://www.jgroups.org">JGroups</a> project to handle communication between database clusters across servers.
				</p>
				<source><![CDATA[
<!ELEMENT distributable EMPTY>
<!ATTLIST distributable
  protocol CDATA "default-minimalthreads.xml"
  timeout  CDATA "1000"
>
]]></source>
				<dl>
					<dt>protocol</dt>
					<dd>
						Defines one of the following:
						<ul>
							<li>Property string representation of the JGroups protocol stack.</li>
							<li>Name of a system resource containing the JGroups XML configuration.</li>
							<li>URL of the JGroups XML configuration file.</li>
							<li>Path of the JGroups XML configuration on the local file system.</li>
						</ul>
						See the JGroup's <a href="http://www.jboss.com/wiki/Wiki.jsp?page=JGroups">Wiki</a> for assistance with customizing the protocol stack.
					</dd>
					<dt>timeout</dt>
					<dd>
						Indicates the number of seconds allowed for JGroups operations.
					</dd>
				</dl>
			</section>
			<section id="sync">
				<title>sync</title>
				<p>
					Defines a strategy for synchronizing a database before activation.
					If the strategy contains JavaBean properties, you can override their default values.
				</p>
				<source>&lt;!ELEMENT sync (<a href="#property">property</a>*)&gt;</source>
				<source><![CDATA[
<!ATTLIST sync
  id    ID    #REQUIRED
  class CDATA #REQUIRED
>
				]]></source>
				<dl>
					<dt>id</dt>
					<dd>
						Uniquely identifies this synchronization strategy.  Used when invoking activation commands.
					</dd>
					<dt>class</dt>
					<dd>
						Class name of an implementation of the <a href="api/net/sf/hajdbc/SynchronizationStrategy.html">net.sf.hajdbc.SynchronizationStrategy</a> interface.
						HA-JDBC provides several out-of-the-box database independent strategies for synchronizing a failed database: 
						<ul>
							<li><a href="api/net/sf/hajdbc/sync/FullSynchronizationStrategy.html">Full</a> - Each table in the inactive database is truncated and data is reinserted from an active database.  This strategy is fastest if the database is way out of sync.</li>
							<li><a href="api/net/sf/hajdbc/sync/DifferentialSynchronizationStrategy.html">Differential</a> - For each table in the inactive database is compared, row by row, with an active database and only changes are updated.  This strategy is fastest if the database is more in sync than not.</li>
							<li><a href="api/net/sf/hajdbc/sync/PassiveSynchronizationStrategy.html">Passive</a> - Does nothing.  Should only be used if databases are known to be in sync.</li>
						</ul>
					</dd>
				</dl>
				<section id="property">
					<title>property</title>
					<source><![CDATA[
<!ELEMENT property (#PCDATA)>
<!ATTLIST property
  name CDATA #REQUIRED
>
]]></source>
					<dl>
						<dt>name</dt>
						<dd>
							The name of the property.
							The value of the property is defined inside this element's contents.
						</dd>
					</dl>
				</section>
			</section>
			<section id="cluster">
				<title>cluster</title>
				<p>
					Defines the nodes and behavior of a database cluster.
				</p>
				<source>&lt;!ELEMENT cluster (<a href="#database">database</a>+|<a href="#datasource">datasource</a>+)&gt;</source>
				<p>
					An HA-JDBC database cluster is accessed in one of two ways: either via the <code>java.sql.DriverManager</code>, or via a <code>javax.sql.DataSource</code>.
				</p>
				<source><![CDATA[
<!ATTLIST cluster
  id                      CDATA                            #REQUIRED
  balancer                (simple|random|round-robin|load) #REQUIRED
  default-sync            IDREF                            #REQUIRED
  dialect                 CDATA                            "net.sf.hajdbc.dialect.DefaultDialect"
  min-threads             CDATA                            "0"
  max-threads             CDATA                            "100"
  max-idle                CDATA                            "60"
  failure-detect-schedule CDATA                            #IMPLIED
  auto-activate-schedule  CDATA                            #IMPLIED
>
]]></source>
				<dl>
					<dt>id</dt>
					<dd>
						Uniquely identifies this database cluster.
					</dd>
					<dt><a href="#balancer">balancer</a></dt>
					<dd>
						Defines the balancer implementation used to distribute read operations among the active nodes of this cluster.
					</dd>
					<dt>default-sync</dt>
					<dd>
						Defines the unique identifier of the synchronization strategy to use by default when activating nodes of this cluster.
					</dd>
					<dt><a href="#dialect">dialect</a></dt>
					<dd>
						The value of this attribute defines either:
						<ul>
							<li>the class name of an implementation of the <a href="api/net/sf/hajdbc/Dialect.html">net.sf.hajdbc.Dialect</a> interface.</li>
							<li>A pre-defined alias as enumerated <a href="#dialect">here</a>.</li>
						</ul>
						HA-JDBC references the configured dialect for any vendor specific SQL.
					</dd>
					<dt>failure-detect-schedule</dt>
					<dd>
						Defines a cron schedule for an asynchronous task that will proactively detect failed database nodes and deactivate them.
						Value should be defined in accordance with the documentation for Quartz <a href="http://www.opensymphony.com/quartz/api/org/quartz/CronTrigger.html">CronTrigger</a>.
						<br/>
						e.g. <code>"0 0/5 * ? * *"</code> will execute every 5 minutes.
					</dd>
					<dt>auto-activate-schedule</dt>
					<dd>
						Defines a cron schedule for an asynchronous task that will automatically activate any database nodes that are alive, but inactive.
						Value should be defined in accordance with the documentation for Quartz <a href="http://www.opensymphony.com/quartz/api/org/quartz/CronTrigger.html">CronTrigger</a>.
						<br/>
						e.g. <code>"0 0 2 ? * *"</code> will execute every day at 2 AM.
					</dd>
					<dt>min-threads</dt>
					<dd>
						Defines the minimum size of the thread pool used for executing write operations.
					</dd>
					<dt>max-threads</dt>
					<dd>
						Defines the maximum size of the thread pool used for executing write operations.
					</dd>
					<dt>max-idle</dt>
					<dd>
						Defines the amount of time for which a non-core idle thread will remain in the thread pool before it is discarded.
					</dd>
				</dl>
				<section id="database">
					<title>database</title>
					<p>
						Defines the databases in this cluster that will be referenced via the java.sql.DriverManager facility.
					</p>
					<source><![CDATA[<!ELEMENT database (driver?, url, property*, (user, password)?)>]]></source>
					<dl>
						<dt>driver</dt>
						<dd>
							Defines the class name of the <acronym title="Java Database Connectivity">JDBC</acronym> driver used to access this database.
						</dd>
						<dt>url</dt>
						<dd>
							Defines the <acronym title="Java Database Connectivity">JDBC</acronym> url used to access this database.
						</dd>
						<dt><a href="#property">property</a></dt>
						<dd>
							Defines a property to be passed to the java.sql.Driver.connect() method.
						</dd>
						<dt>user</dt>
						<dd>
							Defines the user, if any, that HA-JDBC should use to connect to the database during synchronization and database failure detection.
						</dd>
						<dt>password</dt>
						<dd>
							Defines the password, if any, that HA-JDBC should use to connect to the database during synchronization and database failure detection.
						</dd>
					</dl>
					<source><![CDATA[
<!ATTLIST database
	id     CDATA #REQUIRED
	weight CDATA "1"
>
]]></source>
					<dl>
						<dt>id</dt>
						<dd>
							Unique identifer for this database node.
						</dd>
						<dt>weight</dt>
						<dd>
							Defines the relative weight of this database node.
							The weight is used by the balancer implementation to determine which node will service a read request.
						</dd>
					</dl>
				</section>
				<section id="datasource">
					<title>datasource</title>
					<p>
						Defines the databases in this cluster that will be referenced via javax.sql.DataSource.
					</p>
					<source><![CDATA[<!ELEMENT datasource (name, property*, (user, password)?>]]></source>
					<dl>
						<dt>name</dt>
						<dd>
							Defines the <acronym title="Java Naming and Directory Interface">JNDI</acronym> name of this DataSource.
						</dd>
						<dt><a href="#property">property</a></dt>
						<dd>
							Defines a <acronym title="Java Naming and Directory Interface">JNDI</acronym> environment property used when creating an InitialContext from which to lookup this DataSource.
						</dd>
						<dt>user</dt>
						<dd>
							Defines the user, if any, that HA-JDBC should use to connect to the database during synchronization and database failure detection.
						</dd>
						<dt>password</dt>
						<dd>
							Defines the password, if any, that HA-JDBC should use to connect to the database during synchronization and database failure detection.
						</dd>
					</dl>
					<source><![CDATA[
<!ATTLIST datasource
	id     CDATA #REQUIRED
	weight CDATA "1"
>
]]></source>
					<dl>
						<dt>id</dt>
						<dd>
							Unique identifer for this database node.
						</dd>
						<dt>weight</dt>
						<dd>
							Defines the relative weight of this database node.
							The weight is used by the balancer implementation to determine which node will service a read request.
						</dd>
					</dl>
				</section>
			</section>
			<section id="dialect">
				<title>Dialect</title>
				<p>
					The <code>dialect</code> attribute of a cluster determines the SQL syntax used for a given task.
					The value specified for this attribute is either the name of a class that implements <a href="api/net/sf/hajdbc/Dialect.html">net.sf.hajdbc.Dialect</a> (custom implementations are allowed), or, more conveniently, a pre-defined, case-insensitive alias.
					If the dialect attribute is omitted, then <a href="api/net/sf/hajdbc/dialect/DefaultDialect.html">net.sf.hajdbc.dialect.DefaultDialect</a> will be used.
				</p>
				<table>
					<caption>The HA-JDBC distribution contains the following dialect implementations:</caption>
					<tr>
						<th>Vendor</th>
						<th>Dialect</th>
						<th>Aliases</th>
					</tr>
					<tr>
						<td>PostgreSQL</td>
						<td><a href="api/net/sf/hajdbc/dialect/PostgreSQLDialect.html">net.sf.hajdbc.dialect.PostgreSQLDialect</a></td>
						<td>postgresql</td>
					</tr>
					<tr>
						<td>MySQL MaxDB, Oracle</td>
						<td><a href="api/net/sf/hajdbc/dialect/MaxDBDialect.html">net.sf.hajdbc.dialect.MaxDBDialect</a></td>
						<td>maxdb, oracle</td>
					</tr>
					<tr>
						<td>Apache Derby</td>
						<td><a href="api/net/sf/hajdbc/dialect/DerbyDialect.html">net.sf.hajdbc.dialect.DerbyDialect</a></td>
						<td>derby</td>
					</tr>
					<tr>
						<td>HSQLDB</td>
						<td><a href="api/net/sf/hajdbc/dialect/HSQLDBDialect.html">net.sf.hajdbc.dialect.HSQLDBDialect</a></td>
						<td>hsqldb</td>
					</tr>
					<tr>
						<td>IBM DB2</td>
						<td><a href="api/net/sf/hajdbc/dialect/DB2Dialect.html">net.sf.hajdbc.dialect.DB2Dialect</a></td>
						<td>db2</td>
					</tr>
					<tr>
						<td>Default (SQL standard)</td>
						<td><a href="api/net/sf/hajdbc/dialect/DefaultDialect.html">net.sf.hajdbc.dialect.DefaultDialect</a></td>
						<td>mysql, firebird, ingres, mckoi</td>
					</tr>
				</table>
				<note>
					Dialect contributions are more than welcome.  Please submit any additions/updates <a href="http://sourceforge.net/tracker/?group_id=111957&amp;atid=660863">here</a>.
				</note>
			</section>
			<section id="balancer">
				<title>Balancer</title>
				<p>
					When executing a read request from the cluster, HA-JDBC uses the configured balancer strategy to determine which database should service the request.
					Each database can define a weight to affect how it is prioritized by the balancer.
					If no weight is specified for a given database, it is assumed to be 1.
				</p>
				<p>
					HA-JDBC supports four types of balancers:
				</p>
				<dl>
					<dt>simple</dt>
					<dd>
						Requests are always sent to the node with the highest weight.
					</dd>
					<dt>random</dt>
					<dd>
						Requests are sent to a random node.
						Node weights affect the probability that a given node will be chosen.
						The probability that a node will be chosen = <em>weight</em> / <em>total-weight</em>.
					</dd>
					<dt>round-robin</dt>
					<dd>
						Requests are sent to each node in succession.
						A node of weight <em>n</em> will receive <em>n</em> requests before the balancer moves on to the next node.
					</dd>
					<dt>load</dt>
					<dd>
						Requests are sent to the node with the smallest load.
						Node weights affect the calculated load of a given node.
						The load of a node = <em>concurrent-requests</em> / <em>weight</em>.
					</dd>
				</dl>
				<note>
					In general, a node with a weight of 0 will never service a request unless it is the last node in the cluster.
				</note>
			</section>
		</section>
		<section>
			<title>Using HA-JDBC</title>
			<section>
				<title>DriverManager-based Access</title>
				<p>
					Just like your database's <acronym title="Java Database Connectivity">JDBC</acronym> driver, the HA-JDBC driver must first be loaded.
					This can be accomplished in one of two ways:
				</p>
				<ul>
					<li>
						<p>Add <code>net.sf.hajdbc.sql.Driver</code> to your <code>jdbc.drivers</code> system property.</p>
						<p>The JVM will automatically load and register each driver upon startup.</p>
					</li>
					<li>
						<p>
							Explicity load the <code>net.sf.hajdbc.sql.Driver</code> class using <code>Class.forName(...)</code>.
						</p>
						<p>
							Per the <acronym title="Java Database Connectivity">JDBC</acronym> specification, loading the HA-JDBC driver class automatically registers the driver with the <code>DriverManager</code>.
							The HA-JDBC driver will automatically load all underlying <acronym title="Java Database Connectivity">JDBC</acronym> drivers defined within a given cluster.
							This means that you do not need to perform an additional <code>Class.forName(...)</code> to load your database's driver.
						</p>
					</li>
				</ul>
				<p>e.g.</p>
				<p>
					The following is a sample HA-JDBC configuration that uses the DriverManager facility to obtain connections.
				</p>
				<source><![CDATA[
<ha-jdbc>
  <!-- ... -->
  <cluster id="cluster1" balancer="load" dialect="PostgreSQL" default-sync="...">
    <database id="database1">
      <driver>org.postgresql.Driver</driver>
      <url>jdbc:postgresql://server1/database</url>
      <user>postgres</user>
      <password>password</password>
    </datasource>
    <database id="database2">
      <driver>org.postgresql.Driver</driver>
      <url>jdbc:postgresql://server2/database</url>
      <user>postgres</user>
      <password>password</password>
    </datasource>
  </cluster>
</ha-jdbc>
]]></source>
				<p>
					The URL specified in subsequent calls to <code>DriverManager.getConnection(...)</code> follow the pattern:
				</p>
				<p><code>jdbc:ha-jdbc:</code><em>cluster-id</em></p>
				<p>e.g.</p>
				<source><![CDATA[
Connection connection = DriverManager.getConnection("jdbc:ha-jdbc:cluster1", "postgres", "password");
]]></source>
				<p>
					The following is a sample Tomcat configuration that sets up a connection pool for the above HA-JDBC database cluster.
				</p>
				<p>server.xml</p>
				<source><![CDATA[
<Context>
  <!-- ... -->
  <Resource name="jdbc/cluster" type="javax.sql.DataSource"
            username="postgres" password="password" driverClassName="org.postgresql.Driver"
            url="jdbc:ha-jdbc:cluster1"/>
  <!-- ... -->
</Context>
]]></source>
				<p>web.xml</p>
				<source><![CDATA[
<web-app>
  <!-- ... -->
  <resource-env-ref>
    <resource-env-ref-name>jdbc/cluster</resource-env-ref-name>
    <resource-env-ref-type>javax.sql.DataSource</resource-env-ref-type>
  </resource-env-ref>
  <!-- ... -->
</web-app>
]]></source>
				<p>
					Pooled connections are now available via a DataSource at <code>java:comp/env/jdbc/cluster</code>.
				</p>
			</section>
			<section>
				<title>DataSource-based Access</title>
				<p>
					HA-JDBC cluster can also wrap one or more DataSources.
				</p>
				<p>e.g.</p>
				<p>
					The following is a sample HA-JDBC configuration that uses DataSource facilities to obtain connections.
				</p>
				<source><![CDATA[
<ha-jdbc>
  <!-- ... -->
  <cluster id="cluster2" balancer="load" dialect="PostgreSQL" default-sync="...">
    <datasource id="database1">
      <name>java:comp/env/jdbc/database1</name>
    </datasource>
    <datasource id="database2">
      <name>java:comp/env/jdbc/database1</name>
    </datasource>
  </cluster>
</ha-jdbc>
]]></source>
				<p>
					The corresponding Tomcat configuration might look like the following:
				</p>
				<p>server.xml:</p>
				<source><![CDATA[
<Context>
  <!-- ... -->
  <Resource name="jdbc/cluster" factory="org.apache.naming.factory.BeanFactory"
            type="net.sf.hajdbc.sql.DataSource" cluster="cluster2"/>
  
  <Resource name="jdbc/database1" type="javax.sql.DataSource"
            username="postgres" password="password" driverClassName="org.postgresql.Driver"
            url="jdbc:postgresql://server1/database"/>

  <Resource name="jdbc/database2" type="javax.sql.DataSource"
            username="postgres" password="password" driverClassName="org.postgresql.Driver"
            url="jdbc:postgresql://server2/database"/>
  <!-- ... -->
</Context>
]]></source>
				<p>web.xml:</p>
				<source><![CDATA[
<web-app>
  <!-- ... -->
  <resource-env-ref>
    <resource-env-ref-name>jdbc/cluster</resource-env-ref-name>
    <resource-env-ref-type>javax.sql.DataSource</resource-env-ref-type>
  </resource-env-ref>
  <resource-env-ref>
    <resource-env-ref-name>jdbc/database1</resource-env-ref-name>
    <resource-env-ref-type>javax.sql.DataSource</resource-env-ref-type>
  </resource-env-ref>
  <resource-env-ref>
    <resource-env-ref-name>jdbc/database2</resource-env-ref-name>
    <resource-env-ref-type>javax.sql.DataSource</resource-env-ref-type>
  </resource-env-ref>
  <!-- ... -->
</web-app>
]]></source>
				<p>Connections are made to the HA-JDBC cluster via the following code:</p>
				<source><![CDATA[
Context context = new InitialContext();
DataSource dataSource = (DataSource) context.lookup("java:comp/env/jdbc/cluster");
Connection connection = dataSource.getConnection();
]]></source>
			</section>
			<section>
				<title>Unique identifier generation</title>
				<p>The following traditional mechanisms for generating unique identifiers are problematic for clustered database environments:</p>
				<ul>
					<li>Identity columns (only supported by MySQL, HSQLDB, DB2, MS SQL Server, Sybase, etc.) fetched using the <acronym title="Java Database Connectivity">JDBC</acronym> 3.0 <code>ResultSet.getGeneratedKeys()</code> method</li>
					<li>Sequences (only supported by PostgreSQL, MySQL MaxDB (fka SAP DB), Firebird (fka Interbase), Mckoi, Oracle, DB2, etc.)</li>
				</ul>
				<p>
					In general, for unique identifier generation to function correctly, each database node within a cluster needs to independently generate the same sets of identifiers.
					Because of the distributed nature of HA-JDBC, the execution order of 2 simulaneous requests for a new unique identifier cannot be guaranteed to be the same on each database.
					In other words, HA-JDBC cannot guarantee that the same identifier will be generated for each database in the cluster.
					Another reason not to use either of these mechanisms is that they are not supported by every DBMS.
				</p>
				<p>The following alternative unique identifier generation methods are certain to function properly with HA-JDBC for any database:</p>
				<ul>
					<li>High-Low algorithm (often implemented using a Stateless Session EJB)</li>
					<li>UUID algorithms</li>
					<li>Others?</li>
				</ul>
				<p>
					Object-relation mapping (ORM) frameworks (e.g. Hibernate, OJB, Cayenne) typically include implementations of these mechanisms.
				</p>
				<!--p>
					As of version X.Y, HA-JDBC supports those unique identifier generation mechanisms that were problematic in version 1.0 (i.e. identity columns and sequences).
					To support identity columns and sequences, HA-JDBC will acquire a distributable lock on the specific table or sequence before executing the appropriate statements.
					
				</p>
				<section>
					<title>Supported unique identifier mechanisms</title>
					<table>
						<tr>
							<th>Mechanism</th>
							<th>Supported Databases</th>
							<th>Usage</th>
							<th>Consequences</th>
						</tr>
						<tr>
							<td>identity</td>
							<td>MySQL, HSQLDB, Derby/Cloudscape,<br/>DB2, Sybase/SQL Server,<br/>Informix</td>
							<td>INSERT [INTO] my_table ...</td>
							<td>INSERT statements require mutually exclusive lock on table name.</td>
						</tr>
						<tr>
							<td>sequence-SQL:2003</td>
							<td>SQL:2003 syntax</td>
							<td>next value from my_sequence</td>
							<td>Requires mutually exclusive lock on sequence name.</td>
						</tr>
						<tr>
							<td>sequence-PostgreSQL</td>
							<td>PostgreSQL, Mckoi</td>
							<td>nextval('my_sequence')</td>
							<td>Requires mutually exclusive lock on sequence name.</td>
						</tr>
						<tr>
							<td>sequence-MaxDB</td>
							<td>MaxDB/SAPDB, One$DB/Daffodil,<br/>Axion, Oracle, Informix</td>
							<td>my_sequence.nextval</td>
							<td>Requires mutually exclusive lock on sequence name.</td>
						</tr>
						<tr>
							<td>sequence-Firebird</td>
							<td>Firebird/Interbase</td>
							<td>gen_id('my_sequence', 1)</td>
							<td>Requires mutually exclusive lock on sequence name.</td>
						</tr>
						<tr>
							<td>sequence-DB2</td>
							<td>DB2</td>
							<td>nextval from my_sequence</td>
							<td>Requires mutually exclusive lock on sequence name.</td>
						</tr>
						<tr>
							<td>other</td>
							<td>Any database</td>
							<td>Table high-low algorithm, UUID, etc.</td>
							<td>No locking required.</td>
						</tr>
					</table>
					<p>
						HA-JDBC 1.1 requires that the unique identifier generation mechansim be specified using the <em>primary-keys</em> attribute for a given cluster.
						The list of acceptable values is specified in the <em>Mechanism</em> column above.
					</p>
					<p>e.g.</p>
					<source><![CDATA[
	<ha-jdbc>
	  <cluster id="..." balancer="..." default-sync="..." primary-keys="other">
	  </cluster>
	</ha-jdbc>
	]]></source>
				</section>
				<section>
					<title>Performance</title>
					<p>
						As you may have guessed, there are performance implications to using identity columns and sequences.
						Both algorithms introduce per statement regular expression matching and mutex costs, the latter being even more costly for distruted environments.
						Fortunately, the performance penalty for sequences may be improved significantly by utilizing what Hibernate calls a <a href="http://www.hibernate.org/doc/api/org/hibernate/id/SequenceHiLoGenerator.html">Sequence-HiLo algorithm</a>.
					</p>
					<p>
						For best performance, HA-JDBC recommends using a high-low or UUID algorithm so that statement parsing and locking costs can be avoided.
						Object-relation mapping (ORM) frameworks (e.g. Hibernate, OJB, Cayanne) typically include implementations of these mechanisms.
					</p>
				</section-->
			</section>
			<section>
				<title>Advanced <acronym title="Java Database Connectivity">JDBC</acronym> Features</title>
				<section>
					<title>RowSet Implementations</title>
					<p>
						HA-JDBC will work with any RowSet implementation provided that the rowsets are driven by the HA-JDBC driver.
					</p>
					<p>e.g.</p>
					<source><![CDATA[
javax.sql.RowSet rowSet = new com.sun.rowset.CachedRowSetImpl();
rowSet.setCommand("SELECT * FROM TITLES WHERE TYPE = ?");
rowSet.setURL("jdbc:ha-jdbc:cluster");
rowSet.setUsername("postgres");
rowSet.setPassword("password");
rowSet.setString(1, "BIOGRAPHY");
rowSet.execute();
// ...
rowSet.close();
]]></source>
				</section>
			</section>
			<section>
				<title>Failed Database Nodes</title>
				<p>A database node may fail for any number of reasons:</p>
				<ul>
					<li>Network outage</li>
					<li>Hardware failure</li>
					<li>Operating System crash</li>
					<li>Database application crash</li>
					<li>Out of disk space</li>
					<li>No more free connections</li>
					<li>etc.</li>
				</ul>
				<p>
					Failed database nodes are detected after an SQLException is thrown when executing a given database operation.
					A database is determined to have failed if it fails to respond to a trivial query (e.g. SELECT 1).
					The query used to validate that a database is alive is defined by the configured <a href="#dialect">dialect</a>.
				</p>
				<p>
					This query may be executed manually, via the <code>isAlive(String)</code> method on the management interface.
				</p>
				<p>If HA-JDBC determines that a given database has failed:</p>
				<ol>
					<li>An ERROR message is logged.</li>
					<li>The database is removed from the internal registry of active databases.  No more requests will be sent to this database.</li>
					<li>If the cluster was configured to be "distributable", other servers are notified of the failure.</li>
				</ol>
				<p>
					Databases may also be manually deactivated via the <a href="#jmx"><acronym title="Java Management Extensions">JMX</acronym> management interface</a>.
				</p>
				<p>
					Optionally, you can configure HA-JDBC to proactively detect database failures via the <code>failure-detect-schedule</code> attribute.
					The value of this attribute defines a cron expression, which specifies the schedule a database cluster will detect failed databases and deactivate them.
				</p>
				<p>e.g.</p>
				<source><![CDATA[
<ha-jdbc>
  <!-- ... -->
  <cluster id="..." balancer="..." default-sync="..." failure-detect-period="0 * * * * ?">
    <!-- ... -->
  </cluster>
</ha-jdbc>
]]></source>
			</section>
			<section>
				<title>Restoring a Database Node</title>
				<p>
					Before a database node can be reintroduced into a cluster, may first need to be synchronized.
				</p>
				<p>
					HA-JDBC provides several out-of-the-box database independent strategies for synchronizing a failed database:
				</p>
				<ul>
					<li><a href="api/net/sf/hajdbc/sync/FullSynchronizationStrategy.html"><code>Full</code></a> - Each table in the inactive database is truncated and data is reinserted from an active database.  This strategy is fastest if the database is way out of sync.</li>
					<li><a href="api/net/sf/hajdbc/sync/DifferentialSynchronizationStrategy.html"><code>Differential</code></a> - For each table in the inactive database is compared, row by row, with an active database and only changes are updated.  This strategy is fastest if the database is more in sync than not.</li>
					<li><a href="api/net/sf/hajdbc/sync/PassiveSynchronizationStrategy.html"><code>Passive</code></a> - Does nothing.  Should only be used if databases are known to be in sync.</li>
				</ul>
				<p>
					Each synchronization strategy must be defined in the HA-JDBC configuration file.
					A strategy may contain any number of JavaBean properties that can be set in the config file.
				</p>
				<p>e.g.</p>
				<source><![CDATA[
<ha-jdbc>
  <!-- ... -->
  <sync id="diff" class="net.sf.hajdbc.sync.DifferentialSynchronizationStrategy">
    <property name="fetchSize">1000</property>
  </sync>
  <sync id="full" class="net.sf.hajdbc.sync.FullSynchronizationStrategy">
    <property name="fetchSize">1000</property>
    <property name="maxBatchSize">100</property>
  </sync>
  <sync id="passive" class="net.sf.hajdbc.sync.PassiveSynchronizationStrategy"></sync>
  <!-- ... -->
</ha-jdbc>
]]></source>
				<p>
					Although the build-in strategies should be sufficient for most small databases, they are probably not feasible for large databases.
					Synchronizing a large database will typically require vendor specific functionality.
					Custom synchronization strategies may be written by implementing the <a href="api/net/sf/hajdbc/SynchronizationStrategy.html"><code>SynchronizationStrategy</code></a> interface or by extending the functionality of one of the existing strategies.
					For example, I may want to improve the efficiency of the <code>FullSynchronizationStrategy</code> by dropping and re-creating indexes on my database tables.
				</p>
				<p>e.g.</p>
				<source><![CDATA[
public class FasterFullSynchronizationStrategy extends net.sf.hajdbc.sync.FullSynchronizationStrategy
{
    public void synchronize(Connection inactiveConnection, Connection activeConnection, List tableList)
    {
        // For each table, drop all indexes

        super.synchronize(inactiveConnection, activeConnection, tableList);

        // For each table, recreate all indexes
    }
}
]]></source>
				<p>
					Any custom strategies should also be defined in the configuration file.
				</p>
				<p>
					Database activation is triggered manually via the <a href="#jmx"><acronym title="Java Management Extensions">JMX</acronym> management interface</a>.
				</p>
			</section>
			<section id="jmx">
				<title>Database Cluster Administration</title>
				<p>
					HA-JDBC database clusters are administered via a <acronym title="Java Management Extensions">JMX</acronym> management interface: <a href="api/net/sf/hajdbc/DatabaseClusterMBean.html">net.sf.hajdbc.DatabaseClusterMBean</a>
				</p>
				<p>
					The MBean exposes the following methods:
				</p>
				<ul>
					<li><code>getId()</code> - Returns the unique identifier of this cluster.</li>
					<li><code>getVersion()</code> - Returns the HA-JDBC version number.</li>
					<li><code>getActiveDatabases()</code> - Returns a collection of active databases in this cluster.</li>
					<li><code>getInactiveDatabases()</code> - Returns a collection of inactive databases in this cluster.</li>
					<li><code>isAlive(String id)</code> - Tests whether the specified database is responding.</li>
					<li><code>deactivate(String id)</code> - Deactivates the specified database from this cluster.</li>
					<li><code>activate(String id)</code> - Re-activates the specified database from this cluster using the default synchronization strategy for the database cluster.</li>
					<li><code>activate(String id, String strategyId)</code> - Re-activates the specified database from this cluster using the specified synchronization strategy.</li>
					<li><code>addDatabase(String id, String driver, String url)</code> - Adds a new Driver-based database node to this cluster.</li>
					<li><code>addDatabase(String id, String name)</code> - Adds a new DataSource node to this cluster.</li>
					<li><code>removeDatabase(String id)</code> - Removes the specified database node from this cluster.</li>
				</ul>
				<p>
					<acronym title="Java Management Extensions">JMX</acronym> operations can be executed from the <a href="http://java.sun.com/j2se/1.5.0/docs/guide/management/jconsole.html">JConsole</a> interface packaged with JDK 1.5.
				</p>
				<p>
					As an alternative to JConsole (or for Java 1.4 deployments), many 3rd-party <acronym title="Java Management Extensions">JMX</acronym> clients exist:
				</p>
				<ul>
					<li><a href="http://mc4j.org/">MC4J</a></li>
					<li><a href="http://www.jmanage.org/">jManage</a></li>
					<li><a href="http://ejtools.sourceforge.net/applications/jmx.browser/">EJTools JMX Browser</a></li>
					<li><a href="http://panoptesmgmt.sourceforge.net/">Panoptes</a></li>
					<li><a href="http://www.hta-bi.bfh.ch/Projects/ejbplug/">EJAM - Environment for Java Application Management</a></li>
				</ul>
				<p>
					HA-JDBC database cluster may also be administered programatically:
				</p>
				<p>e.g.</p>
				<source><![CDATA[
String clusterId = "cluster1";
String databaseId = "database1";

MBeanServer server = (MBeanServer) MBeanServerFactory.findMBeanServer(null).get(0);
ObjectName name = net.sf.hajdbc.DatabaseClusterFactory.getObjectName(clusterId);

// There are 2 ways to programatically invoke methods on an mbean:

// 1. Generic invoke
Object[] parameterValues = new Object[] { databaseId };
String[] parameterTypes = new String[] { databaseId.getClass().getName() };
server.invoke(name, "deactivate", parameterValues, parameterTypes);
server.invoke(name, "activate", parameterValues, parameterTypes);

// 2. Dynamic proxy
Object object = MBeanServerInvocationHandler.newProxyInstance(server, name, DatabaseClusterMBean.class, false);
DatabaseClusterMBean cluster = (DatabaseClusterMBean) object;
cluster.deactivate(databaseId);
cluster.activate(databaseId);
]]></source>
			</section>
		</section>
	</body>
</document>
